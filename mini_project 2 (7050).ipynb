{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         60000 non-null  int64 \n",
      " 1   comment    60000 non-null  object\n",
      " 2   subreddit  60000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (\"train.csv\")\n",
    "# df.info()\n",
    "# df.shape\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think prestige points not expire ever skins buy available set duration exemple year release another skin vault old one making also limitededition skin also please love god not rerelease skins need grind prestige shop would suck everyone grinded',\n",
       " 'whats going happen refused asilum appeal',\n",
       " 'anecdotal evidence anecdotal clearly everyone meant like people not',\n",
       " 'look dude due respect music people looks like carti either caught much flak maybe sent polite post inviting discussion instead capitalizing every impactful word post carti']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    all_comments = list()\n",
    "    lines = df[\"comment\"].values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        \n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        \n",
    "        emoji = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001FFFF\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        text = emoji.sub(r'', text)\n",
    "        \n",
    "        text = re.sub(r\"i'm\", \"i am\", text)\n",
    "        text = re.sub(r\"he's\", \"he is\", text)\n",
    "        text = re.sub(r\"she's\", \"she is\", text)\n",
    "        text = re.sub(r\"that's\", \"that is\", text)        \n",
    "        text = re.sub(r\"what's\", \"what is\", text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text) \n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)  \n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)  \n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"don't\", \"do not\", text)\n",
    "        text = re.sub(r\"did't\", \"did not\", text)\n",
    "        text = re.sub(r\"can't\", \"can not\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "        text = re.sub(r\"have't\", \"have not\", text)\n",
    "        \n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        \n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        \n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        \n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        \n",
    "        all_comments.append(words)\n",
    "    return all_comments\n",
    "\n",
    "all_comments = clean_text(df)\n",
    "all_comments[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'not': 17260, 'like': 8857, 'would': 7132, 'nt': 6847, 'people': 5844, 'one': 5534, 'get': 4965, 'think': 4333, 'even': 3838, 'really': 3752, ...})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = all_comments\n",
    "fdist = FreqDist()\n",
    "\n",
    "for i in c:\n",
    "    comment_tokens = word_tokenize(i)\n",
    "    for word in comment_tokens:\n",
    "        fdist[word.lower()]+=1\n",
    "\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57559"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 17260),\n",
       " ('like', 8857),\n",
       " ('would', 7132),\n",
       " ('nt', 6847),\n",
       " ('people', 5844),\n",
       " ('one', 5534),\n",
       " ('get', 4965),\n",
       " ('think', 4333),\n",
       " ('even', 3838),\n",
       " ('really', 3752)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 'like'),\n",
       " ('like', 'would'),\n",
       " ('would', 'nt'),\n",
       " ('nt', 'people'),\n",
       " ('people', 'one'),\n",
       " ('one', 'get'),\n",
       " ('get', 'think'),\n",
       " ('think', 'even'),\n",
       " ('even', 'really'),\n",
       " ('really', 'good'),\n",
       " ('good', 'time'),\n",
       " ('time', 'also'),\n",
       " ('also', 'game'),\n",
       " ('game', 'know'),\n",
       " ('know', 'much'),\n",
       " ('much', 'see'),\n",
       " ('see', 'still'),\n",
       " ('still', 'got'),\n",
       " ('got', 'could'),\n",
       " ('could', 'way'),\n",
       " ('way', 'go'),\n",
       " ('go', 'well'),\n",
       " ('well', 'make'),\n",
       " ('make', 'gt'),\n",
       " ('gt', 'right'),\n",
       " ('right', 'first'),\n",
       " ('first', 'going'),\n",
       " ('going', 'actually'),\n",
       " ('actually', 'want'),\n",
       " ('want', 'back'),\n",
       " ('back', 'never'),\n",
       " ('never', 'say'),\n",
       " ('say', 'something'),\n",
       " ('something', 'play'),\n",
       " ('play', 'team'),\n",
       " ('team', 'shit'),\n",
       " ('shit', 'us'),\n",
       " ('us', 'better'),\n",
       " ('better', 'every'),\n",
       " ('every', 'thing'),\n",
       " ('thing', 'pretty'),\n",
       " ('pretty', 'lot'),\n",
       " ('lot', 'years'),\n",
       " ('years', 'need'),\n",
       " ('need', 'said'),\n",
       " ('said', 'bad'),\n",
       " ('bad', 'sure'),\n",
       " ('sure', 'made'),\n",
       " ('made', 'new'),\n",
       " ('new', 'though'),\n",
       " ('though', 'best'),\n",
       " ('best', 'someone'),\n",
       " ('someone', 'great'),\n",
       " ('great', 'probably'),\n",
       " ('probably', 'always'),\n",
       " ('always', 'last'),\n",
       " ('last', 'yeah'),\n",
       " ('yeah', 'lol'),\n",
       " ('lol', 'point'),\n",
       " ('point', 'take'),\n",
       " ('take', 'many'),\n",
       " ('many', 'love'),\n",
       " ('love', 'year'),\n",
       " ('year', 'fucking'),\n",
       " ('fucking', 'let'),\n",
       " ('let', 'fuck'),\n",
       " ('fuck', 'show'),\n",
       " ('show', 'since'),\n",
       " ('since', 'things'),\n",
       " ('things', 'mean'),\n",
       " ('mean', 'world'),\n",
       " ('world', 'man'),\n",
       " ('man', 'look'),\n",
       " ('look', 'getting'),\n",
       " ('getting', 'anything'),\n",
       " ('anything', 'two'),\n",
       " ('two', 'work'),\n",
       " ('work', 'feel'),\n",
       " ('feel', 'ever'),\n",
       " ('ever', 'maybe'),\n",
       " ('maybe', 'everyone'),\n",
       " ('everyone', 'around'),\n",
       " ('around', 'season'),\n",
       " ('season', 'day'),\n",
       " ('day', 'na'),\n",
       " ('na', 'use'),\n",
       " ('use', 'guy'),\n",
       " ('guy', 'makes'),\n",
       " ('makes', 'movie'),\n",
       " ('movie', 'thought'),\n",
       " ('thought', 'big'),\n",
       " ('big', 'already'),\n",
       " ('already', 'long'),\n",
       " ('long', 'end'),\n",
       " ('end', 'enough'),\n",
       " ('enough', 'nothing'),\n",
       " ('nothing', 'part'),\n",
       " ('part', 'least'),\n",
       " ('least', 'without'),\n",
       " ('without', 'yes'),\n",
       " ('yes', 'different'),\n",
       " ('different', 'literally'),\n",
       " ('literally', 'far'),\n",
       " ('far', 'give'),\n",
       " ('give', 'another'),\n",
       " ('another', 'might'),\n",
       " ('might', 'used'),\n",
       " ('used', 'top'),\n",
       " ('top', 'playing'),\n",
       " ('playing', 'saying'),\n",
       " ('saying', 'high'),\n",
       " ('high', 'old'),\n",
       " ('old', 'real'),\n",
       " ('real', 'life'),\n",
       " ('life', 'trying'),\n",
       " ('trying', 'come'),\n",
       " ('come', 'seen'),\n",
       " ('seen', 'watch'),\n",
       " ('watch', 'find'),\n",
       " ('find', 'money'),\n",
       " ('money', 'games'),\n",
       " ('games', 'players'),\n",
       " ('players', 'reason'),\n",
       " ('reason', 'gets'),\n",
       " ('gets', 'trump'),\n",
       " ('trump', 'put'),\n",
       " ('put', 'hard'),\n",
       " ('hard', 'little'),\n",
       " ('little', 'keep'),\n",
       " ('keep', 'whole'),\n",
       " ('whole', 'making'),\n",
       " ('making', 'next'),\n",
       " ('next', 'wrong'),\n",
       " ('wrong', 'bit'),\n",
       " ('bit', 'anyone'),\n",
       " ('anyone', 'either'),\n",
       " ('either', 'away'),\n",
       " ('away', 'done'),\n",
       " ('done', 'oh'),\n",
       " ('oh', 'gon'),\n",
       " ('gon', 'everything'),\n",
       " ('everything', 'looks'),\n",
       " ('looks', 'definitely'),\n",
       " ('definitely', 'win'),\n",
       " ('win', 'believe'),\n",
       " ('believe', 'seems'),\n",
       " ('seems', 'person'),\n",
       " ('person', 'else'),\n",
       " ('else', 'call'),\n",
       " ('call', 'kind'),\n",
       " ('kind', 'live'),\n",
       " ('live', 'change'),\n",
       " ('change', 'less'),\n",
       " ('less', 'player'),\n",
       " ('player', 'stop'),\n",
       " ('stop', 'story'),\n",
       " ('story', 'try'),\n",
       " ('try', 'read'),\n",
       " ('read', 'start'),\n",
       " ('start', 'fun'),\n",
       " ('fun', 'times'),\n",
       " ('times', 'went'),\n",
       " ('went', 'instead'),\n",
       " ('instead', 'stuff'),\n",
       " ('stuff', 'talking'),\n",
       " ('talking', 'almost'),\n",
       " ('almost', 'played'),\n",
       " ('played', 'remember'),\n",
       " ('remember', 'post'),\n",
       " ('post', 'character'),\n",
       " ('character', 'problem'),\n",
       " ('problem', 'may'),\n",
       " ('may', 'music'),\n",
       " ('music', 'left'),\n",
       " ('left', 'fact'),\n",
       " ('fact', 'guys'),\n",
       " ('guys', 'ago'),\n",
       " ('ago', 'place'),\n",
       " ('place', 'dude'),\n",
       " ('dude', 'second'),\n",
       " ('second', 'government'),\n",
       " ('government', 'country'),\n",
       " ('country', 'nice'),\n",
       " ('nice', 'called'),\n",
       " ('called', 'true'),\n",
       " ('true', 'understand'),\n",
       " ('understand', 'tell'),\n",
       " ('tell', 'guess'),\n",
       " ('guess', 'single'),\n",
       " ('single', 'able'),\n",
       " ('able', 'idea'),\n",
       " ('idea', 'sense'),\n",
       " ('sense', 'looking'),\n",
       " ('looking', 'hope'),\n",
       " ('hope', 'yet'),\n",
       " ('yet', 'hit'),\n",
       " ('hit', 'teams'),\n",
       " ('teams', 'level'),\n",
       " ('level', 'fans'),\n",
       " ('fans', 'basically'),\n",
       " ('basically', 'name'),\n",
       " ('name', 'came'),\n",
       " ('came', 'half'),\n",
       " ('half', 'dont'),\n",
       " ('dont', 'started'),\n",
       " ('started', 'agree'),\n",
       " ('agree', 'especially'),\n",
       " ('especially', 'absolutely'),\n",
       " ('absolutely', 'wanted'),\n",
       " ('wanted', 'exactly'),\n",
       " ('exactly', 'damn'),\n",
       " ('damn', 'liquid'),\n",
       " ('liquid', 'power'),\n",
       " ('power', 'full'),\n",
       " ('full', 'side'),\n",
       " ('side', 'episode'),\n",
       " ('episode', 'wait'),\n",
       " ('wait', 'job'),\n",
       " ('job', 'support'),\n",
       " ('support', 'watching'),\n",
       " ('watching', 'means'),\n",
       " ('means', 'help'),\n",
       " ('help', 'series'),\n",
       " ('series', 'god'),\n",
       " ('god', 'song'),\n",
       " ('song', 'saw'),\n",
       " ('saw', 'entire'),\n",
       " ('entire', 'case'),\n",
       " ('case', 'etc'),\n",
       " ('etc', 'completely'),\n",
       " ('completely', 'band'),\n",
       " ('band', 'comment'),\n",
       " ('comment', 'happened'),\n",
       " ('happened', 'hate'),\n",
       " ('hate', 'quite'),\n",
       " ('quite', 'war'),\n",
       " ('war', 'night'),\n",
       " ('night', 'goes'),\n",
       " ('goes', 'free'),\n",
       " ('free', 'imagine'),\n",
       " ('imagine', 'days'),\n",
       " ('days', 'worse'),\n",
       " ('worse', 'care'),\n",
       " ('care', 'using'),\n",
       " ('using', 'kill'),\n",
       " ('kill', 'honestly'),\n",
       " ('honestly', 'run'),\n",
       " ('run', 'anime'),\n",
       " ('anime', 'album'),\n",
       " ('album', 'characters'),\n",
       " ('characters', 'home'),\n",
       " ('home', 'system'),\n",
       " ('system', 'fine'),\n",
       " ('fine', 'wow'),\n",
       " ('wow', 'cool'),\n",
       " ('cool', 'hell'),\n",
       " ('hell', 'head'),\n",
       " ('head', 'mind'),\n",
       " ('mind', 'fan'),\n",
       " ('fan', 'lost'),\n",
       " ('lost', 'matter'),\n",
       " ('matter', 'today'),\n",
       " ('today', 'heard'),\n",
       " ('heard', 'happen'),\n",
       " ('happen', 'please'),\n",
       " ('please', 'amazing'),\n",
       " ('amazing', 'based'),\n",
       " ('based', 'needs'),\n",
       " ('needs', 'close'),\n",
       " ('close', 'took'),\n",
       " ('took', 'line'),\n",
       " ('line', 'coming'),\n",
       " ('coming', 'lmao'),\n",
       " ('lmao', 'video'),\n",
       " ('video', 'league'),\n",
       " ('league', 'reddit'),\n",
       " ('reddit', 'china'),\n",
       " ('china', 'rather'),\n",
       " ('rather', 'death'),\n",
       " ('death', 'scene'),\n",
       " ('scene', 'main'),\n",
       " ('main', 'week'),\n",
       " ('week', 'film'),\n",
       " ('film', 'ones'),\n",
       " ('ones', 'usually'),\n",
       " ('usually', 'buy'),\n",
       " ('buy', 'easy'),\n",
       " ('easy', 'super'),\n",
       " ('super', 'group'),\n",
       " ('group', 'likely'),\n",
       " ('likely', 'school'),\n",
       " ('school', 'comes'),\n",
       " ('comes', 'state'),\n",
       " ('state', 'thanks'),\n",
       " ('thanks', 'later'),\n",
       " ('later', 'white'),\n",
       " ('white', 'eu'),\n",
       " ('eu', 'major'),\n",
       " ('major', 'damage'),\n",
       " ('damage', 'example'),\n",
       " ('example', 'stupid'),\n",
       " ('stupid', 'found'),\n",
       " ('found', 'weird'),\n",
       " ('weird', 'pay'),\n",
       " ('pay', 'kids'),\n",
       " ('kids', 'says'),\n",
       " ('says', 'course'),\n",
       " ('course', 'actual'),\n",
       " ('actual', 'deal'),\n",
       " ('deal', 'small'),\n",
       " ('small', 'seem'),\n",
       " ('seem', 'thinking'),\n",
       " ('thinking', 'issue'),\n",
       " ('issue', 'others'),\n",
       " ('others', 'seeing'),\n",
       " ('seeing', 'shot'),\n",
       " ('shot', 'three'),\n",
       " ('three', 'rest'),\n",
       " ('rest', 'huge'),\n",
       " ('huge', 'pick'),\n",
       " ('pick', 'fight'),\n",
       " ('fight', 'must'),\n",
       " ('must', 'kinda'),\n",
       " ('kinda', 'past'),\n",
       " ('past', 'sometimes'),\n",
       " ('sometimes', 'friends'),\n",
       " ('friends', 'sounds'),\n",
       " ('sounds', 'question'),\n",
       " ('question', 'cause'),\n",
       " ('cause', 'funny'),\n",
       " ('funny', 'dead'),\n",
       " ('dead', 'often'),\n",
       " ('often', 'minutes'),\n",
       " ('minutes', 'set'),\n",
       " ('set', 'behind'),\n",
       " ('behind', 'face'),\n",
       " ('face', 'party'),\n",
       " ('party', 'interesting'),\n",
       " ('interesting', 'friend'),\n",
       " ('friend', 'number'),\n",
       " ('number', 'king'),\n",
       " ('king', 'house'),\n",
       " ('house', 'taking'),\n",
       " ('taking', 'shows'),\n",
       " ('shows', 'told'),\n",
       " ('told', 'lose'),\n",
       " ('lose', 'early'),\n",
       " ('early', 'sub'),\n",
       " ('sub', 'together'),\n",
       " ('together', 'sorry'),\n",
       " ('sorry', 'ball'),\n",
       " ('ball', 'canada'),\n",
       " ('canada', 'role'),\n",
       " ('role', 'chance'),\n",
       " ('chance', 'whatever'),\n",
       " ('whatever', 'opinion'),\n",
       " ('opinion', 'babyrage'),\n",
       " ('babyrage', 'however'),\n",
       " ('however', 'die'),\n",
       " ('die', 'history'),\n",
       " ('history', 'ass'),\n",
       " ('ass', 'hand'),\n",
       " ('hand', 'favorite'),\n",
       " ('favorite', 'media'),\n",
       " ('media', 'family'),\n",
       " ('family', 'happy'),\n",
       " ('happy', 'dps'),\n",
       " ('dps', 'works'),\n",
       " ('works', 'sound'),\n",
       " ('sound', 'given'),\n",
       " ('given', 'worst'),\n",
       " ('worst', 'couple'),\n",
       " ('couple', 'countries'),\n",
       " ('countries', 'felt'),\n",
       " ('felt', 'original'),\n",
       " ('original', 'hear'),\n",
       " ('hear', 'similar'),\n",
       " ('similar', 'vs'),\n",
       " ('vs', 'leave'),\n",
       " ('leave', 'american'),\n",
       " ('american', 'important'),\n",
       " ('important', 'happens'),\n",
       " ('happens', 'experience'),\n",
       " ('experience', 'unless'),\n",
       " ('unless', 'city'),\n",
       " ('city', 'talk'),\n",
       " ('talk', 'move'),\n",
       " ('move', 'working'),\n",
       " ('working', 'released'),\n",
       " ('released', 'black'),\n",
       " ('black', 'possible'),\n",
       " ('possible', 'worth'),\n",
       " ('worth', 'movies'),\n",
       " ('movies', 'ask'),\n",
       " ('ask', 'crazy'),\n",
       " ('crazy', 'low'),\n",
       " ('low', 'amp'),\n",
       " ('amp', 'knew'),\n",
       " ('knew', 'due'),\n",
       " ('due', 'feels'),\n",
       " ('feels', 'points'),\n",
       " ('points', 'weed'),\n",
       " ('weed', 'hours'),\n",
       " ('hours', 'amount'),\n",
       " ('amount', 'become'),\n",
       " ('become', 'goal'),\n",
       " ('goal', 'fair'),\n",
       " ('fair', 'general'),\n",
       " ('general', 'outside'),\n",
       " ('outside', 'except'),\n",
       " ('except', 'wants'),\n",
       " ('wants', 'smoke'),\n",
       " ('smoke', 'op'),\n",
       " ('op', 'law'),\n",
       " ('law', 'clearly'),\n",
       " ('clearly', 'ok'),\n",
       " ('ok', 'im'),\n",
       " ('im', 'killed'),\n",
       " ('killed', 'young'),\n",
       " ('young', 'clear'),\n",
       " ('clear', 'human'),\n",
       " ('human', 'months'),\n",
       " ('months', 'tried'),\n",
       " ('tried', 'kid'),\n",
       " ('kid', 'nobody'),\n",
       " ('nobody', 'political'),\n",
       " ('political', 'holy'),\n",
       " ('holy', 'thank'),\n",
       " ('thank', 'news'),\n",
       " ('news', 'watched'),\n",
       " ('watched', 'gave'),\n",
       " ('gave', 'public'),\n",
       " ('public', 'open'),\n",
       " ('open', 'plays'),\n",
       " ('plays', 'wonder'),\n",
       " ('wonder', 'content'),\n",
       " ('content', 'fire'),\n",
       " ('fire', 'anyway'),\n",
       " ('anyway', 'uk'),\n",
       " ('uk', 'thats'),\n",
       " ('thats', 'joker'),\n",
       " ('joker', 'obviously'),\n",
       " ('obviously', 'anymore'),\n",
       " ('anymore', 'word'),\n",
       " ('word', 'check'),\n",
       " ('check', 'joke'),\n",
       " ('joke', 'break'),\n",
       " ('break', 'thread'),\n",
       " ('thread', 'calling'),\n",
       " ('calling', 'takes'),\n",
       " ('takes', 'control'),\n",
       " ('control', 'mostly'),\n",
       " ('mostly', 'looked'),\n",
       " ('looked', 'score'),\n",
       " ('score', 'easily'),\n",
       " ('easily', 'certain'),\n",
       " ('certain', 'seriously'),\n",
       " ('seriously', 'cut'),\n",
       " ('cut', 'tank'),\n",
       " ('tank', 'current'),\n",
       " ('current', 'water'),\n",
       " ('water', 'okay'),\n",
       " ('okay', 'difference'),\n",
       " ('difference', 'issues'),\n",
       " ('issues', 'knows'),\n",
       " ('knows', 'normal'),\n",
       " ('normal', 'girl'),\n",
       " ('girl', 'poor'),\n",
       " ('poor', 'turn'),\n",
       " ('turn', 'beat'),\n",
       " ('beat', 'rock'),\n",
       " ('rock', 'finally'),\n",
       " ('finally', 'wish'),\n",
       " ('wish', 'vote'),\n",
       " ('vote', 'straight'),\n",
       " ('straight', 'ta'),\n",
       " ('ta', 'simply'),\n",
       " ('simply', 'imo'),\n",
       " ('imo', 'perfect'),\n",
       " ('perfect', 'situation'),\n",
       " ('situation', 'supposed'),\n",
       " ('supposed', 'enjoy'),\n",
       " ('enjoy', 'bullshit'),\n",
       " ('bullshit', 'million'),\n",
       " ('million', 'company'),\n",
       " ('company', 'bunch'),\n",
       " ('bunch', 'middle'),\n",
       " ('middle', 'comments'),\n",
       " ('comments', 'giving'),\n",
       " ('giving', 'act'),\n",
       " ('act', 'type'),\n",
       " ('type', 'article'),\n",
       " ('article', 'women'),\n",
       " ('women', 'moment'),\n",
       " ('moment', 'tonight'),\n",
       " ('tonight', 'edit'),\n",
       " ('edit', 'terrible'),\n",
       " ('terrible', 'classic'),\n",
       " ('classic', 'children'),\n",
       " ('children', 'gone'),\n",
       " ('gone', 'class'),\n",
       " ('class', 'awesome'),\n",
       " ('awesome', 'hero'),\n",
       " ('hero', 'ending'),\n",
       " ('ending', 'dumb'),\n",
       " ('dumb', 'stay'),\n",
       " ('stay', 'version'),\n",
       " ('version', 'bring'),\n",
       " ('bring', 'book'),\n",
       " ('book', 'president'),\n",
       " ('president', 'expect'),\n",
       " ('expect', 'weeks'),\n",
       " ('weeks', 'argument'),\n",
       " ('argument', 'order'),\n",
       " ('order', 'higher'),\n",
       " ('higher', 'front'),\n",
       " ('front', 'social'),\n",
       " ('social', 'defense'),\n",
       " ('defense', 'sad'),\n",
       " ('sad', 'soon'),\n",
       " ('soon', 'force'),\n",
       " ('force', 'strong'),\n",
       " ('strong', 'totally'),\n",
       " ('totally', 'alone'),\n",
       " ('alone', 'personally'),\n",
       " ('personally', 'running'),\n",
       " ('running', 'match'),\n",
       " ('match', 'hold'),\n",
       " ('hold', 'along'),\n",
       " ('along', 'reading'),\n",
       " ('reading', 'majority'),\n",
       " ('majority', 'states'),\n",
       " ('states', 'future'),\n",
       " ('future', 'forget'),\n",
       " ('forget', 'killing'),\n",
       " ('killing', 'russia'),\n",
       " ('russia', 'evidence'),\n",
       " ('evidence', 'fast'),\n",
       " ('fast', 'throw'),\n",
       " ('throw', 'longer'),\n",
       " ('longer', 'red'),\n",
       " ('red', 'form'),\n",
       " ('form', 'police'),\n",
       " ('police', 'sort'),\n",
       " ('sort', 'average'),\n",
       " ('average', 'hey'),\n",
       " ('hey', 'source'),\n",
       " ('source', 'trade'),\n",
       " ('trade', 'hot'),\n",
       " ('hot', 'age'),\n",
       " ('age', 'worked'),\n",
       " ('worked', 'information'),\n",
       " ('information', 'child'),\n",
       " ('child', 'gold'),\n",
       " ('gold', 'short'),\n",
       " ('short', 'lead'),\n",
       " ('lead', 'songs'),\n",
       " ('songs', 'popular'),\n",
       " ('popular', 'fucked'),\n",
       " ('fucked', 'doubt'),\n",
       " ('doubt', 'known'),\n",
       " ('known', 'starting'),\n",
       " ('starting', 'final'),\n",
       " ('final', 'words'),\n",
       " ('words', 'taken'),\n",
       " ('taken', 'jon'),\n",
       " ('jon', 'tv'),\n",
       " ('tv', 'loved'),\n",
       " ('loved', 'needed'),\n",
       " ('needed', 'europe'),\n",
       " ('europe', 'biggest'),\n",
       " ('biggest', 'living'),\n",
       " ('living', 'horde'),\n",
       " ('horde', 'plus'),\n",
       " ('plus', 'books'),\n",
       " ('books', 'common'),\n",
       " ('common', 'allowed'),\n",
       " ('allowed', 'gives'),\n",
       " ('gives', 'stand'),\n",
       " ('stand', 'answer'),\n",
       " ('answer', 'feeling'),\n",
       " ('feeling', 'miss'),\n",
       " ('miss', 'learn'),\n",
       " ('learn', 'internet'),\n",
       " ('internet', 'random'),\n",
       " ('random', 'decent'),\n",
       " ('decent', 'large'),\n",
       " ('large', 'including'),\n",
       " ('including', 'car'),\n",
       " ('car', 'light'),\n",
       " ('light', 'changed'),\n",
       " ('changed', 'glad'),\n",
       " ('glad', 'within'),\n",
       " ('within', 'liked'),\n",
       " ('liked', 'personal'),\n",
       " ('personal', 'late'),\n",
       " ('late', 'meant'),\n",
       " ('meant', 'asked'),\n",
       " ('asked', 'cost'),\n",
       " ('cost', 'record'),\n",
       " ('record', 'decided'),\n",
       " ('decided', 'tho'),\n",
       " ('tho', 'realize'),\n",
       " ('realize', 'save'),\n",
       " ('save', 'paid'),\n",
       " ('paid', 'position'),\n",
       " ('position', 'mention'),\n",
       " ('mention', 'enemy'),\n",
       " ('enemy', 'pass'),\n",
       " ('pass', 'room'),\n",
       " ('room', 'list'),\n",
       " ('list', 'apparently'),\n",
       " ('apparently', 'ability'),\n",
       " ('ability', 'men'),\n",
       " ('men', 'blizzard'),\n",
       " ('blizzard', 'haha'),\n",
       " ('haha', 'action'),\n",
       " ('action', 'battle'),\n",
       " ('battle', 'area'),\n",
       " ('area', 'month'),\n",
       " ('month', 'changes'),\n",
       " ('changes', 'whether'),\n",
       " ('whether', 'turned'),\n",
       " ('turned', 'winning'),\n",
       " ('winning', 'per'),\n",
       " ('per', 'astros'),\n",
       " ('astros', 'america'),\n",
       " ('america', 'became'),\n",
       " ('became', 'cant'),\n",
       " ('cant', 'map'),\n",
       " ('map', 'add'),\n",
       " ('add', 'food'),\n",
       " ('food', 'multiple'),\n",
       " ('multiple', 'legal'),\n",
       " ('legal', 'quality'),\n",
       " ('quality', 'account'),\n",
       " ('account', 'currently'),\n",
       " ('currently', 'surprised'),\n",
       " ('surprised', 'body'),\n",
       " ('body', 'considering'),\n",
       " ('considering', 'career'),\n",
       " ('career', 'died'),\n",
       " ('died', 'english'),\n",
       " ('english', 'business'),\n",
       " ('business', 'piece'),\n",
       " ('piece', 'star'),\n",
       " ('star', 'certainly'),\n",
       " ('certainly', 'air'),\n",
       " ('air', 'insane'),\n",
       " ('insane', 'google'),\n",
       " ('google', 'art'),\n",
       " ('art', 'united'),\n",
       " ('united', 'correct'),\n",
       " ('correct', 'episodes'),\n",
       " ('episodes', 'fake'),\n",
       " ('fake', 'shitty'),\n",
       " ('shitty', 'asking'),\n",
       " ('asking', 'extremely'),\n",
       " ('extremely', 'several'),\n",
       " ('several', 'dark'),\n",
       " ('dark', 'near'),\n",
       " ('near', 'eat'),\n",
       " ('eat', 'complete'),\n",
       " ('complete', 'phone'),\n",
       " ('phone', 'result'),\n",
       " ('result', 'spot'),\n",
       " ('spot', 'round'),\n",
       " ('round', 'fall'),\n",
       " ('fall', 'telling'),\n",
       " ('telling', 'problems'),\n",
       " ('problems', 'recently'),\n",
       " ('recently', 'somehow'),\n",
       " ('somehow', 'ended'),\n",
       " ('ended', 'style'),\n",
       " ('style', 'lower'),\n",
       " ('lower', 'release'),\n",
       " ('release', 'dad'),\n",
       " ('dad', 'nats'),\n",
       " ('nats', 'ah'),\n",
       " ('ah', 'illegal'),\n",
       " ('illegal', 'space'),\n",
       " ('space', 'voice'),\n",
       " ('voice', 'mad'),\n",
       " ('mad', 'skin'),\n",
       " ('skin', 'north'),\n",
       " ('north', 'oil'),\n",
       " ('oil', 'idk'),\n",
       " ('idk', 'third'),\n",
       " ('third', 'losing'),\n",
       " ('losing', 'ground'),\n",
       " ('ground', 'although'),\n",
       " ('although', 'lack'),\n",
       " ('lack', 'writing'),\n",
       " ('writing', 'happening'),\n",
       " ('happening', 'despite'),\n",
       " ('despite', 'special'),\n",
       " ('special', 'listen'),\n",
       " ('listen', 'plenty'),\n",
       " ('plenty', 'health'),\n",
       " ('health', 'simple'),\n",
       " ('simple', 'evil'),\n",
       " ('evil', 'shots'),\n",
       " ('shots', 'missed'),\n",
       " ('missed', 'event'),\n",
       " ('event', 'population'),\n",
       " ('population', 'germany'),\n",
       " ('germany', 'none'),\n",
       " ('none', 'sex'),\n",
       " ('sex', 'exist'),\n",
       " ('exist', 'community'),\n",
       " ('community', 'serious'),\n",
       " ('serious', 'attack'),\n",
       " ('attack', 'hands'),\n",
       " ('hands', 'across'),\n",
       " ('across', 'specific'),\n",
       " ('specific', 'eyes'),\n",
       " ('eyes', 'girls'),\n",
       " ('girls', 'build'),\n",
       " ('build', 'club'),\n",
       " ('club', 'parents'),\n",
       " ('parents', 'overall'),\n",
       " ('overall', 'drive'),\n",
       " ('drive', 'turkey'),\n",
       " ('turkey', 'theory'),\n",
       " ('theory', 'canadian'),\n",
       " ('canadian', 'solo'),\n",
       " ('solo', 'plan'),\n",
       " ('plan', 'seconds'),\n",
       " ('seconds', 'otherwise'),\n",
       " ('otherwise', 'gun'),\n",
       " ('gun', 'alliance'),\n",
       " ('alliance', 'link'),\n",
       " ('link', 'boy'),\n",
       " ('boy', 'members'),\n",
       " ('members', 'brought'),\n",
       " ('brought', 'trash'),\n",
       " ('trash', 'society'),\n",
       " ('society', 'forward'),\n",
       " ('forward', 'reasons'),\n",
       " ('reasons', 'tax'),\n",
       " ('tax', 'considered'),\n",
       " ('considered', 'attention'),\n",
       " ('attention', 'tbh'),\n",
       " ('tbh', 'obvious'),\n",
       " ('obvious', 'sell'),\n",
       " ('sell', 'data'),\n",
       " ('data', 'rights'),\n",
       " ('rights', 'reality'),\n",
       " ('reality', 'showing'),\n",
       " ('showing', 'easier'),\n",
       " ('easier', 'consider'),\n",
       " ('consider', 'nah'),\n",
       " ('nah', 'ways'),\n",
       " ('ways', 'dog'),\n",
       " ('dog', 'events'),\n",
       " ('events', 'rules'),\n",
       " ('rules', 'baby'),\n",
       " ('baby', 'earth'),\n",
       " ('earth', 'blood'),\n",
       " ('blood', 'lane'),\n",
       " ('lane', 'numbers'),\n",
       " ('numbers', 'beautiful'),\n",
       " ('beautiful', 'hurt'),\n",
       " ('hurt', 'pull'),\n",
       " ('pull', 'view'),\n",
       " ('view', 'wall'),\n",
       " ('wall', 'seasons'),\n",
       " ('seasons', 'choice'),\n",
       " ('choice', 'truly'),\n",
       " ('truly', 'plot'),\n",
       " ('plot', 'massive'),\n",
       " ('massive', 'involved'),\n",
       " ('involved', 'wtf'),\n",
       " ('wtf', 'title'),\n",
       " ('title', 'missing'),\n",
       " ('missing', 'starts'),\n",
       " ('starts', 'bro'),\n",
       " ('bro', 'compared'),\n",
       " ('compared', 'queue'),\n",
       " ('queue', 'conspiracy'),\n",
       " ('conspiracy', 'putting'),\n",
       " ('putting', 'cover'),\n",
       " ('cover', 'jesus'),\n",
       " ('jesus', 'quick'),\n",
       " ('quick', 'awful'),\n",
       " ('awful', 'lots'),\n",
       " ('lots', 'base'),\n",
       " ('base', 'term'),\n",
       " ('term', 'exact'),\n",
       " ('exact', 'wins'),\n",
       " ('wins', 'laws'),\n",
       " ('laws', 'assume'),\n",
       " ('assume', 'acting'),\n",
       " ('acting', 'military'),\n",
       " ('military', 'refs'),\n",
       " ('refs', 'heart'),\n",
       " ('heart', 'didnt'),\n",
       " ('didnt', 'u'),\n",
       " ('u', 'caught'),\n",
       " ('caught', 'expected'),\n",
       " ('expected', 'pop'),\n",
       " ('pop', 'mental'),\n",
       " ('mental', 'culture'),\n",
       " ('culture', 'dany'),\n",
       " ('dany', 'lives'),\n",
       " ('lives', 'woman'),\n",
       " ('woman', 'heroes'),\n",
       " ('heroes', 'national'),\n",
       " ('national', 'pro'),\n",
       " ('pro', 'smoking'),\n",
       " ('smoking', 'garbage'),\n",
       " ('garbage', 'rich'),\n",
       " ('rich', 'respect'),\n",
       " ('respect', 'drop'),\n",
       " ('drop', 'racist'),\n",
       " ('racist', 'inside'),\n",
       " ('inside', 'market'),\n",
       " ('market', 'nearly'),\n",
       " ('nearly', 'towards'),\n",
       " ('towards', 'climate'),\n",
       " ('climate', 'safe'),\n",
       " ('safe', 'generally'),\n",
       " ('generally', 'period'),\n",
       " ('period', 'beyond'),\n",
       " ('beyond', 'sleep'),\n",
       " ('sleep', 'disagree'),\n",
       " ('disagree', 'paying'),\n",
       " ('paying', 'race'),\n",
       " ('race', 'entirely'),\n",
       " ('entirely', 'extra'),\n",
       " ('extra', 'screen'),\n",
       " ('screen', 'difficult'),\n",
       " ('difficult', 'office'),\n",
       " ('office', 'european'),\n",
       " ('european', 'football'),\n",
       " ('football', 'absolute'),\n",
       " ('absolute', 'slow'),\n",
       " ('slow', 'box'),\n",
       " ('box', 'election'),\n",
       " ('election', 'companies'),\n",
       " ('companies', 'eventually'),\n",
       " ('eventually', 'field'),\n",
       " ('field', 'fit'),\n",
       " ('fit', 'trust'),\n",
       " ('trust', 'dick'),\n",
       " ('dick', 'german'),\n",
       " ('german', 'bought'),\n",
       " ('bought', 'waiting'),\n",
       " ('waiting', 'context'),\n",
       " ('context', 'chinese'),\n",
       " ('chinese', 'john'),\n",
       " ('john', 'green'),\n",
       " ('green', 'service'),\n",
       " ('service', 'scenes'),\n",
       " ('scenes', 'effect'),\n",
       " ('effect', 'regardless'),\n",
       " ('regardless', 'sick'),\n",
       " ('sick', 'ridiculous'),\n",
       " ('ridiculous', 'decision'),\n",
       " ('decision', 'mother'),\n",
       " ('mother', 'performance'),\n",
       " ('performance', 'zone'),\n",
       " ('zone', 'follow'),\n",
       " ('follow', 'spend'),\n",
       " ('spend', 'zero'),\n",
       " ('zero', 'ya'),\n",
       " ('ya', 'mom'),\n",
       " ('mom', 'calls'),\n",
       " ('calls', 'terms'),\n",
       " ('terms', 'thinks'),\n",
       " ('thinks', 'stopped'),\n",
       " ('stopped', 'count'),\n",
       " ('count', 'walk'),\n",
       " ('walk', 'allow'),\n",
       " ('allow', 'created'),\n",
       " ('created', 'specifically'),\n",
       " ('specifically', 'local'),\n",
       " ('local', 'hair'),\n",
       " ('hair', 'films'),\n",
       " ('films', 'places'),\n",
       " ('places', 'speak'),\n",
       " ('speak', 'shield'),\n",
       " ('shield', 'rate'),\n",
       " ('rate', 'son'),\n",
       " ('son', 'groups'),\n",
       " ('groups', 'following'),\n",
       " ('following', 'blame'),\n",
       " ('blame', 'artist'),\n",
       " ('artist', 'boys'),\n",
       " ('boys', 'explain'),\n",
       " ('explain', 'brain'),\n",
       " ('brain', 'land'),\n",
       " ('land', 'skill'),\n",
       " ('skill', 'rule'),\n",
       " ('rule', 'foreign'),\n",
       " ('foreign', 'claim'),\n",
       " ('claim', 'crime'),\n",
       " ('crime', 'figure'),\n",
       " ('figure', 'picture'),\n",
       " ('picture', 'wife'),\n",
       " ('wife', 'official'),\n",
       " ('official', 'forgot'),\n",
       " ('forgot', 'wan'),\n",
       " ('wan', 'immediately'),\n",
       " ('immediately', 'available'),\n",
       " ('available', 'modern'),\n",
       " ('modern', 'bet'),\n",
       " ('bet', 'choose'),\n",
       " ('choose', 'hour'),\n",
       " ('hour', 'penalty'),\n",
       " ('penalty', 'removed'),\n",
       " ('removed', 'energy'),\n",
       " ('energy', 'building'),\n",
       " ('building', 'truth'),\n",
       " ('truth', 'fighting'),\n",
       " ('fighting', 'kept'),\n",
       " ('kept', 'ult'),\n",
       " ('ult', 'continue'),\n",
       " ('continue', 'hits'),\n",
       " ('hits', 'knowing'),\n",
       " ('knowing', 'overwatch'),\n",
       " ('overwatch', 'b'),\n",
       " ('b', 'member'),\n",
       " ('member', 'push'),\n",
       " ('push', 'language'),\n",
       " ('language', 'process'),\n",
       " ('process', 'eye'),\n",
       " ('eye', 'built'),\n",
       " ('built', 'bigger'),\n",
       " ('bigger', 'deep'),\n",
       " ('deep', 'written'),\n",
       " ('written', 'fantastic'),\n",
       " ('fantastic', 'interested'),\n",
       " ('interested', 'lines'),\n",
       " ('lines', 'leaving'),\n",
       " ('leaving', 'sucks'),\n",
       " ('sucks', 'statement'),\n",
       " ('statement', 'four'),\n",
       " ('four', 'brother'),\n",
       " ('brother', 'double'),\n",
       " ('double', 'cold'),\n",
       " ('cold', 'self'),\n",
       " ('self', 'epstein'),\n",
       " ('epstein', 'parts'),\n",
       " ('parts', 'clean'),\n",
       " ('clean', 'added'),\n",
       " ('added', 'mentioned'),\n",
       " ('mentioned', 'directly'),\n",
       " ('directly', 'older'),\n",
       " ('older', 'helps'),\n",
       " ('helps', 'hopefully'),\n",
       " ('hopefully', 'step'),\n",
       " ('step', 'bc'),\n",
       " ('bc', 'banned'),\n",
       " ('banned', 'hilarious'),\n",
       " ('hilarious', 'e'),\n",
       " ('e', 'regular'),\n",
       " ('regular', 'roll'),\n",
       " ('roll', 'according'),\n",
       " ('according', 'incredible'),\n",
       " ('incredible', 'politics'),\n",
       " ('politics', 'father'),\n",
       " ('father', 'wars'),\n",
       " ('wars', 'forced'),\n",
       " ('forced', 'british'),\n",
       " ('british', 'shooting'),\n",
       " ('shooting', 'loss'),\n",
       " ('loss', 'gear'),\n",
       " ('gear', 'gotten'),\n",
       " ('gotten', 'ton'),\n",
       " ('ton', 'impact'),\n",
       " ('impact', 'summer'),\n",
       " ('summer', 'french'),\n",
       " ('french', 'youtube'),\n",
       " ('youtube', 'mid'),\n",
       " ('mid', 'impossible'),\n",
       " ('impossible', 'range'),\n",
       " ('range', 'option'),\n",
       " ('option', 'focus'),\n",
       " ('focus', 'minute'),\n",
       " ('minute', 'honest'),\n",
       " ('honest', 'smart'),\n",
       " ('smart', 'table'),\n",
       " ('table', 'door'),\n",
       " ('door', 'barely'),\n",
       " ('barely', 'arthur'),\n",
       " ('arthur', 'broken'),\n",
       " ('broken', 'total'),\n",
       " ('total', 'practice'),\n",
       " ('practice', 'potential'),\n",
       " ('potential', 'blue'),\n",
       " ('blue', 'crowd'),\n",
       " ('crowd', 'x'),\n",
       " ('x', 'related'),\n",
       " ('related', 'return'),\n",
       " ('return', 'incredibly'),\n",
       " ('incredibly', 'bill'),\n",
       " ('bill', 'posted'),\n",
       " ('posted', 'spent'),\n",
       " ('spent', 'write'),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_biogram = list(nltk.bigrams(fdist))\n",
    "quotes_biogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('subreddit').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# community_dummies = df['subreddit'].str.get_dummies(sep=' ')\n",
    "# community_dummies[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.comment,df., test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# v = CountVectorizer()\n",
    "# X_train_count = v.fit_transform(X_train.values)\n",
    "# X_train_count.toarray()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# model = MultinomialNB()\n",
    "# model.fit(X_train_count,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # noinspection SpellCheckingInspection\n",
    "# class NaiveBayesClassifier(object):\n",
    "#     def __init__(self, n_gram=1, printing=False):\n",
    "#         self.prior = defaultdict(int)\n",
    "#         self.logprior = {}\n",
    "#         self.bigdoc = defaultdict(list)\n",
    "#         self.loglikelihoods = defaultdict(defaultdict)\n",
    "#         self.V = []\n",
    "#         self.n = n_gram\n",
    "\n",
    "#     def compute_prior_and_bigdoc(self, training_set, training_labels):\n",
    "        \n",
    "#         for x, y in zip(training_set, training_labels):\n",
    "#             all_words = x.split(\" \")\n",
    "#             if self.n == 1:\n",
    "#                 grams = all_words\n",
    "#             else:\n",
    "#                 grams = self.words_to_grams(all_words)\n",
    "\n",
    "#             self.prior[y] += len(grams)\n",
    "#             self.bigdoc[y].append(x)\n",
    "\n",
    "#     def compute_vocabulary(self, documents):\n",
    "#         vocabulary = set()\n",
    "\n",
    "#         for doc in documents:\n",
    "#             for word in doc.split(\" \"):\n",
    "#                 vocabulary.add(word.lower())\n",
    "\n",
    "#         return vocabulary\n",
    "\n",
    "#     def count_word_in_classes(self):\n",
    "#         counts = {}\n",
    "#         for c in list(self.bigdoc.keys()):\n",
    "#             docs = self.bigdoc[c]\n",
    "#             counts[c] = defaultdict(int)\n",
    "#             for doc in docs:\n",
    "#                 words = doc.split(\" \")\n",
    "#                 for word in words:\n",
    "#                     counts[c][word] += 1\n",
    "\n",
    "#         return counts\n",
    "\n",
    "#     def train(self, training_set, training_labels, alpha=1):\n",
    "#         # Get number of documents\n",
    "#         N_doc = len(training_set)\n",
    "\n",
    "#         # Get vocabulary used in training set\n",
    "#         self.V = self.compute_vocabulary(training_set)\n",
    "\n",
    "#         # Create bigdoc\n",
    "#         for x, y in zip(training_set, training_labels):\n",
    "#             self.bigdoc[y].append(x)\n",
    "\n",
    "#         # Get set of all classes\n",
    "#         all_classes = set(training_labels)\n",
    "\n",
    "#         # Compute a dictionary with all word counts for each class\n",
    "#         self.word_count = self.count_word_in_classes()\n",
    "\n",
    "#         # For each class\n",
    "#         for c in all_classes:\n",
    "#             # Get number of documents for that class\n",
    "#             N_c = float(sum(training_labels == c))\n",
    "\n",
    "#             # Compute logprior for class\n",
    "#             self.logprior[c] = np.log(N_c / N_doc)\n",
    "\n",
    "#             # Calculate the sum of counts of words in current class\n",
    "#             total_count = 0\n",
    "#             for word in self.V:\n",
    "#                 total_count += self.word_count[c][word]\n",
    "\n",
    "#             # For every word, get the count and compute the log-likelihood for this class\n",
    "#             for word in self.V:\n",
    "#                 count = self.word_count[c][word]\n",
    "#                 self.loglikelihoods[c][word] = np.log((count + alpha) / (total_count + alpha * len(self.V)))\n",
    "\n",
    "#     def predict(self, test_doc):\n",
    "#         sums = {\n",
    "#             0: 0,\n",
    "#             1: 0,\n",
    "#         }\n",
    "#         for c in self.bigdoc.keys():\n",
    "#             sums[c] = self.logprior[c]\n",
    "#             words = test_doc.split(\" \")\n",
    "#             for word in words:\n",
    "#                if word in self.V:\n",
    "#                    sums[c] += self.loglikelihoods[c][word]\n",
    "\n",
    "#         return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBclassifier = NaiveBayesClassifier(n_gram=1)\n",
    "# NBclassifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = NBclassifier.predict(test)\n",
    "# print(np.exp(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

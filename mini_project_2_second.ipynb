{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         60000 non-null  int64 \n",
      " 1   comment    60000 non-null  object\n",
      " 2   subreddit  60000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (\"train.csv\")\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I think prestige points should not expire ever...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Whats going to happen with them if they will b...</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anecdotal evidence is anecdotal. Clearly by “e...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Look dude, with all due respect, your music is...</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hope he gets the doomhammer back!</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment        subreddit\n",
       "0   0  I think prestige points should not expire ever...  leagueoflegends\n",
       "1   1  Whats going to happen with them if they will b...           europe\n",
       "2   2  Anecdotal evidence is anecdotal. Clearly by “e...    gameofthrones\n",
       "3   3  Look dude, with all due respect, your music is...            Music\n",
       "4   4                  Hope he gets the doomhammer back!              wow"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#NAME?                                                                                                                                                                                                                                                                                                                                   5\n",
       "Favorite anime and why?\\n\\nFavorite movie and why?\\n\\nFavorite game and why?\\n\\nFavorite book and why?\\n\\n[](#curious)                                                                                                                                                                                                                   4\n",
       "I understood that reference                                                                                                                                                                                                                                                                                                              4\n",
       "Especially these days                                                                                                                                                                                                                                                                                                                    3\n",
       "r/technicallythetruth                                                                                                                                                                                                                                                                                                                    3\n",
       "                                                                                                                                                                                                                                                                                                                                        ..\n",
       "Well, he has an ence Flair. So I guess he is just doing it for fun. Looks like he also has the same success as Ence after they benched aleksi. None.                                                                                                                                                                                     1\n",
       "Which ones?\\n\\n\\nAre we talking about being best and competitive? Because you're talking to a PvP player here who couldn't give less of a shit about what works in Raids or high M+.\\n\\nBeing able to do all roles adequately alone is good enough for me. You can take Feral and Balance to high rating in Arena, and Resto as well.    1\n",
       "European championship sounds weird even if it’s technically correct                                                                                                                                                                                                                                                                      1\n",
       "&gt;Odyn\\n\\n&gt;Halls of Lightning\\n\\nWuh                                                                                                                                                                                                                                                                                                1\n",
       "Agreed, I was being partially facetious... I know there’s no conspiracy.  \\n\\nI do think it’s at least strange that the two countries defeated by the Allies in WW2 end up cornering the global scat porn market just 35-40 years later, when porn hits the mainstream.                                                                  1\n",
       "Name: comment, Length: 59969, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_counts, df['subreddit'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.04708333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(df['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
